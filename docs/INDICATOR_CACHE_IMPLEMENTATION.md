# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Indicator-Level Caching

Ø§ÛŒÙ† Ø³Ù†Ø¯ Ù†Ø­ÙˆÙ‡ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Indicator-Level Cache Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

---

## ğŸ¯ Ù‡Ø¯Ù

Ø§ÙØ²ÙˆØ¯Ù† ÛŒÚ© Ù„Ø§ÛŒÙ‡ cache Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª indicator Ú©Ù‡:
- âœ… Indicators Ø±Ø§ cache Ù…ÛŒâ€ŒÚ©Ù†Ø¯ (Ù†Ù‡ ÙÙ‚Ø· Signals)
- âœ… Ø§Ø² DataFrame hash Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- âœ… ØªØºÛŒÛŒØ±Ø§Øª config Ø±Ø§ ØªØ´Ø®ÛŒØµ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
- âœ… Ù…Ø³ØªÙ‚Ù„ Ø§Ø² Signal Cache Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯

---

## ğŸ“Š Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¯Ùˆ Ø³Ø·Ø­ÛŒ Cache

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Request: Generate Signal                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Level 1: Signal Cache       â”‚ â† Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª
      â”‚  (TimeframeScoreCache)       â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
              â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
              â”‚   Hit?    â”‚
              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        Yes â†â”€â”€â”€â”€â”€â”€â”€â”˜        No
         â†“                    â†“
    Return Signal      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Level 2:        â”‚ â† ğŸ†• Ø¬Ø¯ÛŒØ¯
                       â”‚ Indicator Cache â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                       â”‚   Hit?    â”‚
                       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                 Yes â†â”€â”€â”€â”€â”€â”€â”€â”˜        No
                  â†“                    â†“
          Skip calculation      Calculate Indicators
          Use cached indicators â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
          Run Analyzers (50-70% Ø³Ø±ÛŒØ¹â€ŒØªØ±!)
                  â†“
          Calculate Score
                  â†“
          Update both caches
                  â†“
          Return Signal
```

---

## ğŸ”§ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ

### 1ï¸âƒ£ Ú©Ù„Ø§Ø³ IndicatorCache

**ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯:** `signal_generation/shared/indicator_cache.py`

```python
"""
Indicator Cache - Cache for technical indicator calculations

Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ù…Ø­Ø§Ø³Ø¨Ø§Øª indicator Ø±Ø§ cache Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø² Ù…Ø­Ø§Ø³Ø¨Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ
Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ú©Ù†Ø¯.

Ù…Ø²Ø§ÛŒØ§:
- Ú©Ø§Ù‡Ø´ 50-70% Ø²Ù…Ø§Ù† Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø®Ø§Øµ
- Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ backtesting Ùˆ parameter optimization
- Ù…Ø³ØªÙ‚Ù„ Ø§Ø² Signal Cache
"""

from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
import pandas as pd
import hashlib
import time
import logging
from threading import Lock

logger = logging.getLogger(__name__)


@dataclass
class CachedIndicators:
    """Indicators Ú©Ø´ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÚ© DataFrame"""

    # DataFrame Ø¨Ø§ indicator columns
    df_with_indicators: pd.DataFrame

    # Hash of input data (Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ØªØºÛŒÛŒØ±Ø§Øª)
    data_hash: str

    # Hash of config (Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ØªØºÛŒÛŒØ±Ø§Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª)
    config_hash: str

    # Ø²Ù…Ø§Ù† Ù…Ø­Ø§Ø³Ø¨Ù‡
    calculated_at: float = field(default_factory=time.time)

    # Ø¢Ù…Ø§Ø±
    hit_count: int = 0

    def is_valid(self, data_hash: str, config_hash: str, max_age: float) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹ØªØ¨Ø§Ø± cache"""

        # Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯Ù‡
        if data_hash != self.data_hash:
            return False

        # Ø¨Ø±Ø±Ø³ÛŒ ØªØºÛŒÛŒØ± config
        if config_hash != self.config_hash:
            return False

        # Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ø± cache
        age = time.time() - self.calculated_at
        if age > max_age:
            return False

        return True


class IndicatorCache:
    """
    Cache Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª indicator

    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ indicators Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³:
    1. Hash of DataFrame (Ø¢Ø®Ø±ÛŒÙ† N Ú©Ù†Ø¯Ù„)
    2. Hash of config (ØªÙ†Ø¸ÛŒÙ…Ø§Øª indicator)

    cache Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

    Ù…Ø«Ø§Ù„:
        >>> cache = IndicatorCache(config)
        >>>
        >>> # Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø± - Ù…Ø­Ø§Ø³Ø¨Ù‡
        >>> df_with_indicators = cache.get_or_calculate(
        ...     df=raw_df,
        ...     calculator=indicator_calculator,
        ...     context=context
        ... )
        >>> # Ø¨Ø§Ø± Ø¯ÙˆÙ… - Ø§Ø² cache
        >>> df_with_indicators = cache.get_or_calculate(
        ...     df=same_raw_df,
        ...     calculator=indicator_calculator,
        ...     context=context
        ... )  # Ø³Ø±ÛŒØ¹! Ø§Ø² cache Ù…ÛŒâ€ŒØ¢ÛŒØ¯
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize IndicatorCache

        Args:
            config: Configuration dictionary
        """
        self.config = config

        # Cache storage: {cache_key: CachedIndicators}
        self._cache: Dict[str, CachedIndicators] = {}

        # Lock for thread safety
        self._lock = Lock()

        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
        cache_config = self.config.get('indicator_cache', {})
        self.enabled = cache_config.get('enabled', True)
        self.max_cache_age = cache_config.get('max_cache_age_seconds', 3600)  # 1 hour
        self.max_cache_entries = cache_config.get('max_entries', 100)
        self.hash_window = cache_config.get('hash_window', 10)  # Ø¢Ø®Ø±ÛŒÙ† N Ú©Ù†Ø¯Ù„

        # Ø¢Ù…Ø§Ø±
        self.total_hits = 0
        self.total_misses = 0
        self.total_calculations = 0

        logger.info(
            f"IndicatorCache initialized "
            f"(enabled={self.enabled}, max_age={self.max_cache_age}s, "
            f"max_entries={self.max_cache_entries})"
        )

    def _compute_data_hash(self, df: pd.DataFrame) -> str:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ hash Ø§Ø² DataFrame

        ÙÙ‚Ø· Ø¢Ø®Ø±ÛŒÙ† N Ú©Ù†Ø¯Ù„ Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯ (Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª)
        """
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¢Ø®Ø±ÛŒÙ† N Ú©Ù†Ø¯Ù„
        window = min(self.hash_window, len(df))
        recent_data = df[['open', 'high', 'low', 'close', 'volume']].tail(window)

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ bytes Ùˆ hash
        data_bytes = recent_data.values.tobytes()
        return hashlib.md5(data_bytes).hexdigest()

    def _compute_config_hash(self) -> str:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ hash Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª indicator
        """
        # ÙÙ‚Ø· Ø¨Ø®Ø´ indicators Ø±Ø§ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±ÛŒÙ…
        indicators_config = self.config.get('indicators', {})

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string Ùˆ hash
        config_str = str(sorted(indicators_config.items()))
        return hashlib.md5(config_str.encode()).hexdigest()

    def _get_cache_key(self, symbol: str, timeframe: str, data_hash: str) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ú©Ù„ÛŒØ¯ cache"""
        return f"{symbol}_{timeframe}_{data_hash}"

    def get_or_calculate(
        self,
        df: pd.DataFrame,
        symbol: str,
        timeframe: str,
        calculator: Any,  # IndicatorCalculator instance
        context: Any  # AnalysisContext instance
    ) -> pd.DataFrame:
        """
        Ø¯Ø±ÛŒØ§ÙØª indicators Ø§Ø² cache ÛŒØ§ Ù…Ø­Ø§Ø³Ø¨Ù‡

        Args:
            df: DataFrame Ø®Ø§Ù… (Ø¨Ø¯ÙˆÙ† indicators)
            symbol: Ù†Ù…Ø§Ø¯
            timeframe: ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…
            calculator: IndicatorCalculator instance
            context: AnalysisContext instance

        Returns:
            DataFrame Ø¨Ø§ indicator columns
        """
        if not self.enabled:
            # Cache ØºÛŒØ±ÙØ¹Ø§Ù„ - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø³ØªÙ‚ÛŒÙ…
            calculator.calculate_all(context)
            self.total_calculations += 1
            return context.df

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ hashes
        data_hash = self._compute_data_hash(df)
        config_hash = self._compute_config_hash()
        cache_key = self._get_cache_key(symbol, timeframe, data_hash)

        with self._lock:
            # Ø¨Ø±Ø±Ø³ÛŒ cache
            if cache_key in self._cache:
                cached = self._cache[cache_key]

                # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
                if cached.is_valid(data_hash, config_hash, self.max_cache_age):
                    # Cache hit!
                    cached.hit_count += 1
                    self.total_hits += 1

                    logger.debug(
                        f"âœ“ Indicator Cache HIT for {symbol} {timeframe} "
                        f"(hits={cached.hit_count}, age={time.time() - cached.calculated_at:.0f}s)"
                    )

                    # Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† DataFrame Ø§Ø² cache
                    context.df = cached.df_with_indicators.copy()
                    return context.df

        # Cache miss - Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¬Ø¯Ø¯
        self.total_misses += 1
        self.total_calculations += 1

        logger.debug(
            f"âœ— Indicator Cache MISS for {symbol} {timeframe} "
            f"(reason: not_found or invalid)"
        )

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ indicators
        start_time = time.time()
        calculator.calculate_all(context)
        calc_time = (time.time() - start_time) * 1000  # ms

        logger.debug(f"  Calculated indicators in {calc_time:.0f}ms")

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± cache
        with self._lock:
            self._cache[cache_key] = CachedIndicators(
                df_with_indicators=context.df.copy(),
                data_hash=data_hash,
                config_hash=config_hash,
                calculated_at=time.time(),
                hit_count=0
            )

            # Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø¬Ù… cache
            if len(self._cache) > self.max_cache_entries:
                self._evict_old_entries()

        return context.df

    def _evict_old_entries(self):
        """Ø­Ø°Ù Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† entries"""
        # Ø­Ø°Ù 20% Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±ÛŒÙ† entries
        num_to_remove = int(self.max_cache_entries * 0.2)

        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø²Ù…Ø§Ù†
        sorted_entries = sorted(
            self._cache.items(),
            key=lambda x: x[1].calculated_at
        )

        # Ø­Ø°Ù
        for key, _ in sorted_entries[:num_to_remove]:
            del self._cache[key]

        logger.debug(f"Evicted {num_to_remove} old cache entries")

    def invalidate_symbol(self, symbol: str):
        """Ø­Ø°Ù ØªÙ…Ø§Ù… cache Ù‡Ø§ÛŒ ÛŒÚ© symbol"""
        with self._lock:
            keys_to_remove = [k for k in self._cache.keys() if k.startswith(f"{symbol}_")]
            for key in keys_to_remove:
                del self._cache[key]

            if keys_to_remove:
                logger.info(f"Invalidated {len(keys_to_remove)} cache entries for {symbol}")

    def clear_all(self):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ù„ cache"""
        with self._lock:
            count = len(self._cache)
            self._cache.clear()
            logger.info(f"Cleared entire indicator cache ({count} entries)")

    def get_statistics(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± cache"""
        with self._lock:
            total_requests = self.total_hits + self.total_misses
            hit_rate = (self.total_hits / total_requests * 100) if total_requests > 0 else 0.0

            return {
                'enabled': self.enabled,
                'total_entries': len(self._cache),
                'total_hits': self.total_hits,
                'total_misses': self.total_misses,
                'total_calculations': self.total_calculations,
                'hit_rate': hit_rate,
                'max_entries': self.max_cache_entries,
                'max_age_seconds': self.max_cache_age,
            }

    def log_statistics(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø¯Ø± log"""
        stats = self.get_statistics()

        logger.info("=" * 60)
        logger.info("ğŸ“Š Indicator Cache Statistics")
        logger.info("=" * 60)
        logger.info(f"Enabled: {stats['enabled']}")
        logger.info(f"Cache entries: {stats['total_entries']}/{stats['max_entries']}")
        logger.info(f"Cache hits: {stats['total_hits']}")
        logger.info(f"Cache misses: {stats['total_misses']}")
        logger.info(f"Hit rate: {stats['hit_rate']:.1f}%")
        logger.info(f"Total calculations: {stats['total_calculations']}")
        logger.info("=" * 60)
```

---

## 2ï¸âƒ£ Ø§Ø¯ØºØ§Ù… Ø¨Ø§ IndicatorCalculator

**ÙØ§ÛŒÙ„:** `signal_generation/shared/indicator_calculator.py`

```python
from signal_generation.shared.indicator_cache import IndicatorCache

class IndicatorCalculator:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.orchestrator = IndicatorOrchestrator(config)

        # ğŸ†• Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Indicator Cache
        self.indicator_cache = IndicatorCache(config)

        self._register_indicators()

    def calculate_all(self, context) -> None:
        """
        Ù…Ø­Ø§Ø³Ø¨Ù‡ indicators Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² cache
        """
        # ğŸ†• Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² cache
        context.df = self.indicator_cache.get_or_calculate(
            df=context.df,
            symbol=context.symbol,
            timeframe=context.timeframe,
            calculator=self,  # Ø®ÙˆØ¯Ø´
            context=context
        )

        # Ø§Ú¯Ø± Ø§Ø² cache Ø¢Ù…Ø¯ØŒ Ø§ÛŒÙ† Ø®Ø· Ø§Ø¬Ø±Ø§ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯
        # Ø§Ú¯Ø± cache Ù†Ø¨ÙˆØ¯ØŒ get_or_calculate Ø®ÙˆØ¯Ø´ calculate_all Ø±Ø§ ØµØ¯Ø§ Ù…ÛŒâ€ŒØ²Ù†Ø¯
```

---

## 3ï¸âƒ£ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Config

**ÙØ§ÛŒÙ„:** `config.yaml`

```yaml
# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Indicator Cache (ğŸ†• Ø¬Ø¯ÛŒØ¯)
indicator_cache:
  enabled: true                    # ÙØ¹Ø§Ù„/ØºÛŒØ±ÙØ¹Ø§Ù„
  max_cache_age_seconds: 3600      # Ø­Ø¯Ø§Ú©Ø«Ø± Ø¹Ù…Ø± cache (1 Ø³Ø§Ø¹Øª)
  max_entries: 100                 # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ entries
  hash_window: 10                  # ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¢Ø®Ø± Ø¨Ø±Ø§ÛŒ hash

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Signal Cache (Ù…ÙˆØ¬ÙˆØ¯)
timeframe_score_cache:
  enabled: true
  max_cache_age_hours: 24
```

---

## ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯

### Scenario 1: ØªØºÛŒÛŒØ± ØªÙ†Ø¸ÛŒÙ…Ø§Øª scoring

```python
# Ø¨Ø¯ÙˆÙ† Indicator Cache
for config_variant in [config1, config2, config3]:
    orchestrator.config = config_variant
    signal = await orchestrator._generate_signal_with_context('BTCUSDT', '1h')
    # Ù‡Ø± Ø¨Ø§Ø±: Indicators (400ms) + Analyzers (100ms) + Score (50ms) = 550ms
    # Total: 550ms Ã— 3 = 1650ms

# Ø¨Ø§ Indicator Cache
for config_variant in [config1, config2, config3]:
    orchestrator.config = config_variant
    signal = await orchestrator._generate_signal_with_context('BTCUSDT', '1h')
    # Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø±: 550ms
    # Ø¨Ø§Ø± Ø¯ÙˆÙ… Ùˆ Ø³ÙˆÙ…: Indicators (5ms) + Analyzers (100ms) + Score (50ms) = 155ms
    # Total: 550ms + 155ms + 155ms = 860ms

# Ø¨Ù‡Ø¨ÙˆØ¯: 48% Ø³Ø±ÛŒØ¹â€ŒØªØ±
```

### Scenario 2: Backtesting

```python
# Test 5 Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø±ÙˆÛŒ 1000 Ú©Ù†Ø¯Ù„

# Ø¨Ø¯ÙˆÙ† Indicator Cache
for strategy in strategies:
    for candle_set in candle_sets:  # 1000 set
        calculate_indicators()  # 400ms Ã— 1000 Ã— 5 = 2,000,000ms (33 Ø¯Ù‚ÛŒÙ‚Ù‡!)

# Ø¨Ø§ Indicator Cache
for candle_set in candle_sets:  # 1000 set
    calculate_indicators()  # ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø±: 400ms Ã— 1000 = 400,000ms

for strategy in strategies[1:]:  # 4 Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ø¯ÛŒÚ¯Ø±
    for candle_set in candle_sets:
        get_from_cache()  # 5ms Ã— 1000 Ã— 4 = 20,000ms

# Total: 400,000ms + 20,000ms = 420,000ms (7 Ø¯Ù‚ÛŒÙ‚Ù‡)
# Ø¨Ù‡Ø¨ÙˆØ¯: 79% Ø³Ø±ÛŒØ¹â€ŒØªØ±! ğŸš€
```

---

## ğŸ§ª ØªØ³Øª

```python
# tests/unit/signal_generation/test_indicator_cache.py

import pytest
from signal_generation.shared.indicator_cache import IndicatorCache

def test_cache_hit_with_same_data(config, sample_df):
    """ØªØ³Øª: Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ ÛŒÚ©Ø³Ø§Ù†ØŒ Ø§Ø² cache Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯"""
    cache = IndicatorCache(config)

    # Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø±
    result1 = cache.get_or_calculate(
        df=sample_df, symbol='BTCUSDT', timeframe='1h',
        calculator=mock_calculator, context=mock_context
    )

    # Ø¨Ø§Ø± Ø¯ÙˆÙ… Ø¨Ø§ Ù‡Ù…Ø§Ù† Ø¯Ø§Ø¯Ù‡
    result2 = cache.get_or_calculate(
        df=sample_df, symbol='BTCUSDT', timeframe='1h',
        calculator=mock_calculator, context=mock_context
    )

    # Ø¨Ø±Ø±Ø³ÛŒ
    assert cache.total_hits == 1
    assert cache.total_misses == 1
    pd.testing.assert_frame_equal(result1, result2)


def test_cache_miss_with_different_data(config, sample_df):
    """ØªØ³Øª: Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ù…ØªÙØ§ÙˆØªØŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯"""
    cache = IndicatorCache(config)

    # Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø±
    result1 = cache.get_or_calculate(
        df=sample_df, symbol='BTCUSDT', timeframe='1h',
        calculator=mock_calculator, context=mock_context
    )

    # Ø¨Ø§Ø± Ø¯ÙˆÙ… Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ù…ØªÙØ§ÙˆØª
    different_df = sample_df.copy()
    different_df['close'].iloc[-1] += 100  # ØªØºÛŒÛŒØ± Ù‚ÛŒÙ…Øª

    result2 = cache.get_or_calculate(
        df=different_df, symbol='BTCUSDT', timeframe='1h',
        calculator=mock_calculator, context=mock_context
    )

    # Ø¨Ø±Ø±Ø³ÛŒ
    assert cache.total_hits == 0
    assert cache.total_misses == 2  # Ù‡Ø± Ø¯Ùˆ Ø¨Ø§Ø± miss


def test_cache_miss_with_different_config(config, sample_df):
    """ØªØ³Øª: Ø¨Ø§ config Ù…ØªÙØ§ÙˆØªØŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯"""
    cache = IndicatorCache(config)

    # Ø§ÙˆÙ„ÛŒÙ† Ø¨Ø§Ø±
    result1 = cache.get_or_calculate(
        df=sample_df, symbol='BTCUSDT', timeframe='1h',
        calculator=mock_calculator, context=mock_context
    )

    # ØªØºÛŒÛŒØ± config
    cache.config['indicators']['ema_periods'] = [10, 20]  # ØªØºÛŒÛŒØ±

    # Ø¨Ø§Ø± Ø¯ÙˆÙ… Ø¨Ø§ Ù‡Ù…Ø§Ù† Ø¯Ø§Ø¯Ù‡ Ø§Ù…Ø§ config Ù…ØªÙØ§ÙˆØª
    result2 = cache.get_or_calculate(
        df=sample_df, symbol='BTCUSDT', timeframe='1h',
        calculator=mock_calculator, context=mock_context
    )

    # Ø¨Ø±Ø±Ø³ÛŒ
    assert cache.total_misses == 2  # Ù‡Ø± Ø¯Ùˆ Ø¨Ø§Ø± miss (config ØªØºÛŒÛŒØ± Ú©Ø±Ø¯)
```

---

## ğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ø§Ù†ØªØ¸Ø§Ø±ÛŒ

### Hit Rate Ø¨Ø± Ø§Ø³Ø§Ø³ use case:

| Use Case | Hit Rate | Ø¨Ù‡Ø¨ÙˆØ¯ Ø²Ù…Ø§Ù† |
|----------|----------|------------|
| Real-time trading (ØªÚ© symbol) | 30-50% | 20-30% |
| Real-time trading (Ú†Ù†Ø¯ symbol) | 50-70% | 40-50% |
| Backtesting | 80-95% | 70-85% |
| Parameter optimization | 90-98% | 85-95% |

---

## ğŸ’¡ Ù†Ú©Ø§Øª Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ

### âœ… Ù…Ø²Ø§ÛŒØ§:
1. Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø¨Ø±Ø§ÛŒ backtesting Ùˆ optimization
2. Ú©Ø§Ù‡Ø´ CPU usage
3. Ù…Ø³ØªÙ‚Ù„ Ø§Ø² Signal Cache
4. Thread-safe

### âš ï¸ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§:
1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø­Ø§ÙØ¸Ù‡: ~50-100MB Ø¨Ø±Ø§ÛŒ 100 entries
2. ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ DataFrame Ù‡Ø§ÛŒ ÛŒÚ©Ø³Ø§Ù† Ù…ÙÛŒØ¯ Ø§Ø³Øª
3. Ù†ÛŒØ§Ø² Ø¨Ù‡ tuning Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ hash_window

### ğŸ¯ Ú©Ø§Ø±Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ:
- âœ… Backtesting Ú†Ù†Ø¯ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ
- âœ… Parameter optimization (grid search)
- âœ… A/B testing
- âš ï¸ Real-time (ÙØ§ÛŒØ¯Ù‡ Ú©Ù…ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯ - Signal Cache Ú©Ø§ÙÛŒ Ø§Ø³Øª)

---

## ğŸš€ Ú¯Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ

1. âœ… Ø§ÛŒØ¬Ø§Ø¯ `indicator_cache.py` (2-3 Ø³Ø§Ø¹Øª)
2. âœ… Ø§Ø¯ØºØ§Ù… Ø¨Ø§ `IndicatorCalculator` (1 Ø³Ø§Ø¹Øª)
3. âœ… Ù†ÙˆØ´ØªÙ† ØªØ³Øªâ€ŒÙ‡Ø§ (1-2 Ø³Ø§Ø¹Øª)
4. âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª config (30 Ø¯Ù‚ÛŒÙ‚Ù‡)
5. âœ… Ù…Ø³ØªÙ†Ø¯Ø§Øª Ùˆ Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ (1 Ø³Ø§Ø¹Øª)

**Total: 5-7 Ø³Ø§Ø¹Øª**

---

## ğŸ“ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Indicator-Level Cache ÛŒÚ© Ø¨Ù‡Ø¨ÙˆØ¯ **optional** Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ø³Ù†Ø§Ø±ÛŒÙˆÙ‡Ø§ÛŒ Ø®Ø§Øµ (backtesting, optimization) Ø¨Ø³ÛŒØ§Ø± Ù…ÙÛŒØ¯ Ø§Ø³Øª:

```
âœ… Real-time trading: Signal Cache Ú©Ø§ÙÛŒ Ø§Ø³Øª
âœ… Backtesting: Indicator Cache + Signal Cache â†’ 70-85% Ø³Ø±ÛŒØ¹â€ŒØªØ±
âœ… Optimization: Indicator Cache + Signal Cache â†’ 85-95% Ø³Ø±ÛŒØ¹â€ŒØªØ±
```

---

**Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ:** 2025-01-20
