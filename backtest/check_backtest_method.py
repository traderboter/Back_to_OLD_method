#!/usr/bin/env python3
"""
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ´Ø®ÛŒØµ Ø±ÙˆØ´ Backtest (OLD vs NEW)

Ø§Ø³ØªÙØ§Ø¯Ù‡:
  python backtest/check_backtest_method.py v2_20251120_002427
  python backtest/check_backtest_method.py v2_20251120_002407

ÛŒØ§ Ø¨Ø¯ÙˆÙ† Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø®Ø±ÛŒÙ† backtest:
  python backtest/check_backtest_method.py
"""

import json
import sys
from pathlib import Path
from datetime import datetime


def check_backtest_method(folder_name=None):
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± backtest

    Args:
        folder_name: Ù†Ø§Ù… ÙÙˆÙ„Ø¯Ø± backtest (Ù…Ø«Ù„Ø§Ù‹ v2_20251120_002427)
                    Ø§Ú¯Ø± None Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ø®Ø±ÛŒÙ† ÙÙˆÙ„Ø¯Ø± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    """
    # Ù…Ø³ÛŒØ± ÙÙˆÙ„Ø¯Ø± backtest_results
    base_dir = Path(__file__).parent.parent  # ÛŒÚ© Ù¾ÙˆØ´Ù‡ Ø¨Ø§Ù„Ø§ØªØ± (root)
    results_dir = base_dir / 'backtest_results'

    if not results_dir.exists():
        print(f"âŒ ÙÙˆÙ„Ø¯Ø± {results_dir} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return None

    # Ø§Ú¯Ø± folder_name Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ØŒ Ø¢Ø®Ø±ÛŒÙ† ÙÙˆÙ„Ø¯Ø± Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†
    if folder_name is None:
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ ÙÙˆÙ„Ø¯Ø±Ù‡Ø§ÛŒ v2_*
        v2_folders = sorted([f for f in results_dir.iterdir() if f.is_dir() and f.name.startswith('v2_')])

        if not v2_folders:
            print(f"âŒ Ù‡ÛŒÚ† ÙÙˆÙ„Ø¯Ø± backtest Ø¯Ø± {results_dir} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            return None

        # Ø¢Ø®Ø±ÛŒÙ† ÙÙˆÙ„Ø¯Ø± (Ø¨Ø± Ø§Ø³Ø§Ø³ timestamp Ø¯Ø± Ù†Ø§Ù…)
        backtest_folder = v2_folders[-1]
        print(f"ğŸ“ Ø¢Ø®Ø±ÛŒÙ† backtest Ù¾ÛŒØ¯Ø§ Ø´Ø¯: {backtest_folder.name}")
    else:
        backtest_folder = results_dir / folder_name

        if not backtest_folder.exists():
            print(f"âŒ ÙÙˆÙ„Ø¯Ø± {backtest_folder} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            print(f"\nÙÙˆÙ„Ø¯Ø±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:")
            for f in sorted(results_dir.iterdir()):
                if f.is_dir() and f.name.startswith('v2_'):
                    print(f"  - {f.name}")
            return None

    # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ config.json
    config_file = backtest_folder / 'config.json'

    if not config_file.exists():
        print(f"âŒ ÙØ§ÛŒÙ„ {config_file} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return None

    # Ø®ÙˆØ§Ù†Ø¯Ù† config.json
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† config.json: {e}")
        return None

    # ØªØ´Ø®ÛŒØµ Ø±ÙˆØ´
    print("\n" + "=" * 70)
    print(f"ğŸ“Š BACKTEST METHOD DETECTION")
    print("=" * 70)
    print(f"ğŸ“ Folder: {backtest_folder.name}")
    print(f"ğŸ“„ Config: {config_file}")
    print("=" * 70)

    # 1. Ø¨Ø±Ø±Ø³ÛŒ scoring_method
    scoring_method = config.get('signal_processing', {}).get('scoring', {}).get('scoring_method', 'unknown')

    # 2. Ø¨Ø±Ø±Ø³ÛŒ use_multi_tf_aggregation
    use_multi_tf = config.get('orchestrator', {}).get('use_multi_tf_aggregation', None)

    # 3. Ø¨Ø±Ø±Ø³ÛŒ old_system settings
    old_system = config.get('signal_processing', {}).get('scoring', {}).get('old_system', {})
    symbol_perf = old_system.get('symbol_performance_enabled', None)
    correlation_safety = old_system.get('correlation_safety_enabled', None)
    use_rr_confluence = old_system.get('use_rr_based_confluence', None)
    max_final_score = old_system.get('max_final_score', None)

    # 4. Ø¨Ø±Ø±Ø³ÛŒ validation thresholds
    validation = config.get('validation', {})
    min_signal_score = validation.get('min_signal_score', None)
    strong_threshold = validation.get('strong_signal_threshold', None)

    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
    print(f"\nğŸ”‘ KEY INDICATORS:")
    print(f"  scoring_method:              {scoring_method.upper()}")
    print(f"  use_multi_tf_aggregation:    {use_multi_tf}")
    print(f"\nâš™ï¸  OLD SYSTEM FEATURES:")
    print(f"  symbol_performance_enabled:  {symbol_perf}")
    print(f"  correlation_safety_enabled:  {correlation_safety}")
    print(f"  use_rr_based_confluence:     {use_rr_confluence}")
    print(f"  max_final_score:             {max_final_score} {'(unlimited)' if max_final_score == 0 else '(limited)' if max_final_score else ''}")
    print(f"\nğŸ“Š VALIDATION THRESHOLDS:")
    print(f"  min_signal_score:            {min_signal_score}")
    print(f"  strong_signal_threshold:     {strong_threshold}")

    # ØªØ¹ÛŒÛŒÙ† Ø±ÙˆØ´ Ù†Ù‡Ø§ÛŒÛŒ
    print("\n" + "=" * 70)

    if scoring_method == 'old' and use_multi_tf == True:
        method = 'OLD'
        emoji = 'âš™ï¸'
        description = 'Multi-TF Aggregation + 13 Multipliers'
    elif scoring_method == 'new' and use_multi_tf == False:
        method = 'NEW'
        emoji = 'âœ…'
        description = 'Best Signal Selection (8 Analyzers)'
    elif scoring_method == 'hybrid':
        method = 'HYBRID'
        emoji = 'ğŸ”€'
        description = 'Mixed approach'
    else:
        method = 'UNKNOWN'
        emoji = 'â“'
        description = 'Cannot determine method clearly'

    print(f"{emoji} METHOD DETECTED: {method}")
    print(f"ğŸ“ Description: {description}")
    print("=" * 70)

    # Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡
    print(f"\nğŸ“‹ COMPARISON WITH STANDARD METHODS:")
    print(f"{'Attribute':<35} {'OLD':<15} {'NEW':<15} {'Current':<15}")
    print("-" * 80)
    print(f"{'scoring_method':<35} {'old':<15} {'new':<15} {scoring_method:<15}")
    print(f"{'use_multi_tf_aggregation':<35} {'True':<15} {'False':<15} {str(use_multi_tf):<15}")
    print(f"{'min_signal_score':<35} {'200':<15} {'60':<15} {str(min_signal_score):<15}")
    print(f"{'strong_signal_threshold':<35} {'500':<15} {'150':<15} {str(strong_threshold):<15}")
    print(f"{'max_final_score':<35} {'0 (unlimited)':<15} {'300':<15} {str(max_final_score):<15}")
    print(f"{'OLD system features enabled':<35} {'Yes':<15} {'No':<15} {'Yes' if symbol_perf else 'No':<15}")

    print("\n" + "=" * 70 + "\n")

    return {
        'method': method,
        'scoring_method': scoring_method,
        'use_multi_tf_aggregation': use_multi_tf,
        'min_signal_score': min_signal_score,
        'strong_threshold': strong_threshold,
        'max_final_score': max_final_score,
        'old_system_enabled': symbol_perf
    }


def list_all_backtests():
    """Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… backtestÙ‡Ø§ Ø¨Ø§ Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡"""
    base_dir = Path(__file__).parent.parent
    results_dir = base_dir / 'backtest_results'

    if not results_dir.exists():
        print(f"âŒ ÙÙˆÙ„Ø¯Ø± {results_dir} ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ù…Ù‡ ÙÙˆÙ„Ø¯Ø±Ù‡Ø§ÛŒ v2_*
    v2_folders = sorted([f for f in results_dir.iterdir() if f.is_dir() and f.name.startswith('v2_')])

    if not v2_folders:
        print(f"âŒ Ù‡ÛŒÚ† ÙÙˆÙ„Ø¯Ø± backtest ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return

    print("\n" + "=" * 100)
    print(f"ğŸ“Š ALL BACKTESTS SUMMARY")
    print("=" * 100)
    print(f"{'Folder Name':<30} {'Method':<10} {'Multi-TF':<10} {'Min Score':<12} {'Date/Time':<20}")
    print("-" * 100)

    for folder in v2_folders:
        config_file = folder / 'config.json'

        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)

                scoring_method = config.get('signal_processing', {}).get('scoring', {}).get('scoring_method', '?')
                use_multi_tf = config.get('orchestrator', {}).get('use_multi_tf_aggregation', '?')
                min_score = config.get('validation', {}).get('min_signal_score', '?')

                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ø§Ø² Ù†Ø§Ù… ÙÙˆÙ„Ø¯Ø± (v2_20251120_002427)
                parts = folder.name.split('_')
                if len(parts) >= 3:
                    date_str = parts[1]  # 20251120
                    time_str = parts[2]  # 002427
                    try:
                        dt = datetime.strptime(f"{date_str}_{time_str}", "%Y%m%d_%H%M%S")
                        datetime_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                    except:
                        datetime_str = folder.name
                else:
                    datetime_str = folder.name

                method = 'OLD' if scoring_method == 'old' else 'NEW' if scoring_method == 'new' else 'HYBRID'

                print(f"{folder.name:<30} {method:<10} {str(use_multi_tf):<10} {str(min_score):<12} {datetime_str:<20}")

            except:
                print(f"{folder.name:<30} {'ERROR':<10} {'?':<10} {'?':<12} {'?':<20}")
        else:
            print(f"{folder.name:<30} {'NO CONFIG':<10} {'?':<10} {'?':<12} {'?':<20}")

    print("=" * 100 + "\n")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description='Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¯Ø± Backtest (OLD vs NEW)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:
  python backtest/check_backtest_method.py v2_20251120_002427
  python backtest/check_backtest_method.py v2_20251120_002407
  python backtest/check_backtest_method.py --list
  python backtest/check_backtest_method.py
        """
    )

    parser.add_argument(
        'folder',
        nargs='?',
        default=None,
        help='Ù†Ø§Ù… ÙÙˆÙ„Ø¯Ø± backtest (Ù…Ø«Ù„Ø§Ù‹ v2_20251120_002427). Ø§Ú¯Ø± Ù†Ø¯Ø§Ø¯Ù‡ Ø´ÙˆØ¯ØŒ Ø¢Ø®Ø±ÛŒÙ† ÙÙˆÙ„Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯'
    )

    parser.add_argument(
        '--list', '-l',
        action='store_true',
        help='Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… backtestÙ‡Ø§'
    )

    args = parser.parse_args()

    if args.list:
        list_all_backtests()
    else:
        result = check_backtest_method(args.folder)

        if result:
            sys.exit(0)
        else:
            sys.exit(1)
