#!/usr/bin/env python3
"""
ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬ Ø¨Ú©â€ŒØªØ³Øª Ø¨Ø±Ø§ÛŒ ØªØ£ÛŒÛŒØ¯ Ø§ÛŒÙ†Ú©Ù‡ Stop Loss Ùˆ Target Ù¾ÙˆÛŒØ§ Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ø¨Ø± Ø§Ø³Ø§Ø³ ATR Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
"""

import pandas as pd
import json
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
sns.set_style('whitegrid')


def load_trades(csv_path):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ CSV Ù…Ø¹Ø§Ù…Ù„Ø§Øª"""
    print(f"ğŸ“‚ Loading trades from: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"âœ… Loaded {len(df)} trades")
    return df


def extract_atr_from_metadata(metadata_str):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ATR Ø§Ø² Ø±Ø´ØªÙ‡ JSON Ù…ØªØ§Ø¯ÛŒØªØ§"""
    try:
        metadata = json.loads(metadata_str)
        return metadata.get('indicators', {}).get('atr', None)
    except:
        return None


def calculate_sl_metrics(df):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Stop Loss"""

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ATR Ø§Ø² metadata
    print("\nğŸ” Extracting ATR from metadata...")
    df['atr'] = df['metadata_json'].apply(extract_atr_from_metadata)

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ SL Ø§Ø² Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯
    print("ğŸ“ Calculating SL distances...")
    df['sl_distance'] = abs(df['entry_price'] - df['stop_loss'])

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Target Ø§Ø² Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯
    df['target_distance'] = abs(df['take_profit'] - df['entry_price'])

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ATR Percent (Ù†Ø³Ø¨Øª Ø¨Ù‡ Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯)
    df['atr_percent'] = (df['atr'] / df['entry_price']) * 100

    # ØªØ¹ÛŒÛŒÙ† Volatility Regime Ø¨Ø± Ø§Ø³Ø§Ø³ ATR%
    def get_volatility_regime(atr_pct):
        if pd.isna(atr_pct):
            return 'unknown'
        elif atr_pct < 0.5:
            return 'low'
        elif atr_pct <= 1.5:
            return 'normal'
        else:
            return 'high'

    df['volatility_regime'] = df['atr_percent'].apply(get_volatility_regime)

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Multiplier (SL_distance / ATR)
    df['sl_atr_multiplier'] = df['sl_distance'] / df['atr']

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Risk-Reward Ratio
    df['rr_ratio'] = df['target_distance'] / df['sl_distance']

    return df


def analyze_sl_variability(df):
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ SL Ø«Ø§Ø¨Øª Ø§Ø³Øª ÛŒØ§ Ù…ØªØºÛŒØ±"""

    print("\n" + "="*80)
    print("ğŸ“Š ANALYSIS 1: Stop Loss Variability")
    print("="*80)

    # Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ SL Distance
    sl_stats = df['sl_distance'].describe()
    print("\nğŸ“ˆ Stop Loss Distance Statistics:")
    print(sl_stats)

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¶Ø±ÛŒØ¨ ØªØºÛŒÛŒØ±Ø§Øª (CV)
    cv = (df['sl_distance'].std() / df['sl_distance'].mean()) * 100
    print(f"\nğŸ“‰ Coefficient of Variation (CV): {cv:.2f}%")

    if cv < 5:
        print("âŒ RESULT: Stop Loss appears to be FIXED (low variability)")
    elif cv < 20:
        print("âš ï¸  RESULT: Stop Loss has LIMITED variability")
    else:
        print("âœ… RESULT: Stop Loss is DYNAMIC (high variability)")

    # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù‚Ø§Ø¯ÛŒØ± ÛŒÚ©ØªØ§
    unique_sl = df['sl_distance'].nunique()
    total_trades = len(df)
    uniqueness_ratio = (unique_sl / total_trades) * 100

    print(f"\nğŸ”¢ Unique SL values: {unique_sl} out of {total_trades} trades ({uniqueness_ratio:.1f}%)")

    if uniqueness_ratio > 80:
        print("âœ… RESULT: High uniqueness suggests DYNAMIC calculation")
    elif uniqueness_ratio > 50:
        print("âš ï¸  RESULT: Moderate uniqueness")
    else:
        print("âŒ RESULT: Low uniqueness suggests possible FIXED values")


def analyze_atr_correlation(df):
    """Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨ÛŒÙ† ATR Ùˆ SL Distance"""

    print("\n" + "="*80)
    print("ğŸ“Š ANALYSIS 2: ATR Correlation with SL Distance")
    print("="*80)

    # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ ATR Ù†Ø¯Ø§Ø±Ù†Ø¯
    df_clean = df.dropna(subset=['atr', 'sl_distance'])

    if len(df_clean) == 0:
        print("âŒ No ATR data available for analysis")
        return

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
    correlation = df_clean['atr'].corr(df_clean['sl_distance'])
    print(f"\nğŸ“ˆ Correlation between ATR and SL Distance: {correlation:.4f}")

    if correlation > 0.8:
        print("âœ… RESULT: STRONG positive correlation - SL is ATR-based")
    elif correlation > 0.5:
        print("âš ï¸  RESULT: MODERATE positive correlation")
    else:
        print("âŒ RESULT: WEAK correlation - SL may not be ATR-based")


def analyze_sl_multipliers(df):
    """ØªØ­Ù„ÛŒÙ„ Multiplier (SL_distance / ATR) Ùˆ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ volatility regime"""

    print("\n" + "="*80)
    print("ğŸ“Š ANALYSIS 3: SL-ATR Multipliers by Volatility Regime")
    print("="*80)

    df_clean = df.dropna(subset=['sl_atr_multiplier', 'volatility_regime'])

    if len(df_clean) == 0:
        print("âŒ No data available for analysis")
        return

    # Ø¢Ù…Ø§Ø± Multiplier Ø¨Ø±Ø§ÛŒ Ù‡Ø± Volatility Regime
    print("\nğŸ“Š SL-ATR Multiplier Statistics by Volatility Regime:")
    print("-" * 80)

    regime_stats = df_clean.groupby('volatility_regime')['sl_atr_multiplier'].agg([
        ('count', 'count'),
        ('mean', 'mean'),
        ('median', 'median'),
        ('std', 'std'),
        ('min', 'min'),
        ('max', 'max')
    ]).round(2)

    print(regime_stats)

    # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡
    print("\nğŸ“‹ Expected Multipliers (from documentation):")
    print("   â€¢ Low volatility:    1.5Ã— ATR")
    print("   â€¢ Normal volatility: 2.0Ã— ATR")
    print("   â€¢ High volatility:   3.0Ã— ATR")

    print("\nğŸ” Checking if actual multipliers match expected values:")

    expected_multipliers = {
        'low': 1.5,
        'normal': 2.0,
        'high': 3.0
    }

    for regime in ['low', 'normal', 'high']:
        if regime in regime_stats.index:
            actual = regime_stats.loc[regime, 'mean']
            expected = expected_multipliers[regime]
            diff = abs(actual - expected)
            diff_pct = (diff / expected) * 100

            if diff_pct < 10:
                status = "âœ… MATCH"
            elif diff_pct < 25:
                status = "âš ï¸  CLOSE"
            else:
                status = "âŒ MISMATCH"

            print(f"   {regime.upper():8} - Expected: {expected:.1f}x, Actual: {actual:.2f}x, Diff: {diff_pct:.1f}% {status}")


def analyze_rr_ratios(df):
    """ØªØ­Ù„ÛŒÙ„ Risk-Reward Ratios"""

    print("\n" + "="*80)
    print("ğŸ“Š ANALYSIS 4: Risk-Reward Ratio Analysis")
    print("="*80)

    df_clean = df.dropna(subset=['rr_ratio'])

    if len(df_clean) == 0:
        print("âŒ No RR ratio data available")
        return

    # Ø¢Ù…Ø§Ø± ØªÙˆØµÛŒÙÛŒ
    rr_stats = df_clean['rr_ratio'].describe()
    print("\nğŸ“ˆ Risk-Reward Ratio Statistics:")
    print(rr_stats)

    print("\nğŸ“‹ Expected Range: 1.8 - 3.0")

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ú†Ù†Ø¯ Ø¯Ø±ØµØ¯ Ø¯Ø± Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± Ù‡Ø³ØªÙ†Ø¯
    in_range = df_clean['rr_ratio'].between(1.8, 3.0).sum()
    total = len(df_clean)
    pct_in_range = (in_range / total) * 100

    print(f"\nâœ… {in_range} out of {total} trades ({pct_in_range:.1f}%) have RR ratio in expected range")

    if pct_in_range > 80:
        print("âœ… RESULT: Most trades follow expected RR ratio guidelines")
    elif pct_in_range > 50:
        print("âš ï¸  RESULT: Moderate adherence to RR ratio guidelines")
    else:
        print("âŒ RESULT: Many trades deviate from expected RR ratio")


def analyze_by_direction(df):
    """ØªØ­Ù„ÛŒÙ„ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¹Ø§Ù…Ù„Ø§Øª LONG Ùˆ SHORT"""

    print("\n" + "="*80)
    print("ğŸ“Š ANALYSIS 5: Comparison of LONG vs SHORT Trades")
    print("="*80)

    df_clean = df.dropna(subset=['sl_atr_multiplier', 'rr_ratio'])

    if len(df_clean) == 0:
        print("âŒ No data available")
        return

    print("\nğŸ“Š Statistics by Trade Direction:")
    print("-" * 80)

    direction_stats = df_clean.groupby('direction').agg({
        'sl_atr_multiplier': ['mean', 'std', 'min', 'max'],
        'rr_ratio': ['mean', 'std', 'min', 'max'],
        'trade_id': 'count'
    }).round(2)

    print(direction_stats)

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ LONG Ùˆ SHORT ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ ÛŒÚ©Ø³Ø§Ù† Ù‡Ø³ØªÙ†Ø¯
    if 'long' in df_clean['direction'].str.lower().values and 'short' in df_clean['direction'].str.lower().values:
        long_avg = df_clean[df_clean['direction'].str.lower() == 'long']['sl_atr_multiplier'].mean()
        short_avg = df_clean[df_clean['direction'].str.lower() == 'short']['sl_atr_multiplier'].mean()

        diff_pct = abs(long_avg - short_avg) / ((long_avg + short_avg) / 2) * 100

        print(f"\nğŸ” SL Multiplier difference between LONG and SHORT: {diff_pct:.1f}%")

        if diff_pct < 10:
            print("âœ… RESULT: LONG and SHORT use similar SL logic (DYNAMIC)")
        else:
            print("âš ï¸  RESULT: LONG and SHORT have different SL logic")


def create_visualizations(df):
    """Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒ"""

    print("\n" + "="*80)
    print("ğŸ“Š Creating Visualizations...")
    print("="*80)

    df_clean = df.dropna(subset=['atr', 'sl_distance', 'sl_atr_multiplier', 'rr_ratio'])

    if len(df_clean) < 10:
        print("âŒ Insufficient data for visualizations")
        return

    # Ø§ÛŒØ¬Ø§Ø¯ figure Ø¨Ø§ 6 subplot
    fig, axes = plt.subplots(3, 2, figsize=(16, 18))
    fig.suptitle('Dynamic Stop Loss & Target Analysis', fontsize=16, fontweight='bold')

    # 1. Scatter: ATR vs SL Distance
    ax1 = axes[0, 0]
    ax1.scatter(df_clean['atr'], df_clean['sl_distance'], alpha=0.5, s=30)
    ax1.set_xlabel('ATR')
    ax1.set_ylabel('SL Distance')
    ax1.set_title('ATR vs Stop Loss Distance')
    ax1.grid(True, alpha=0.3)

    # Ø®Ø· Ø±Ú¯Ø±Ø³ÛŒÙˆÙ†
    z = np.polyfit(df_clean['atr'], df_clean['sl_distance'], 1)
    p = np.poly1d(z)
    ax1.plot(df_clean['atr'], p(df_clean['atr']), "r--", alpha=0.8, linewidth=2,
             label=f'Linear fit: y={z[0]:.2f}x+{z[1]:.2f}')
    ax1.legend()

    # 2. Histogram: SL Distance Distribution
    ax2 = axes[0, 1]
    ax2.hist(df_clean['sl_distance'], bins=50, alpha=0.7, color='steelblue', edgecolor='black')
    ax2.set_xlabel('SL Distance')
    ax2.set_ylabel('Frequency')
    ax2.set_title('Stop Loss Distance Distribution')
    ax2.axvline(df_clean['sl_distance'].mean(), color='red', linestyle='--',
                linewidth=2, label=f'Mean: {df_clean["sl_distance"].mean():.2f}')
    ax2.legend()
    ax2.grid(True, alpha=0.3, axis='y')

    # 3. Boxplot: SL Multiplier by Volatility Regime
    ax3 = axes[1, 0]
    df_clean.boxplot(column='sl_atr_multiplier', by='volatility_regime', ax=ax3)
    ax3.set_xlabel('Volatility Regime')
    ax3.set_ylabel('SL-ATR Multiplier')
    ax3.set_title('SL-ATR Multiplier by Volatility Regime')
    ax3.get_figure().suptitle('')  # Ø­Ø°Ù Ø¹Ù†ÙˆØ§Ù† Ø§Ø¶Ø§ÙÛŒ

    # Ø®Ø·ÙˆØ· Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡
    ax3.axhline(1.5, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label='Low (1.5x)')
    ax3.axhline(2.0, color='orange', linestyle=':', linewidth=1.5, alpha=0.7, label='Normal (2.0x)')
    ax3.axhline(3.0, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label='High (3.0x)')
    ax3.legend()
    ax3.grid(True, alpha=0.3, axis='y')

    # 4. Histogram: Risk-Reward Ratio
    ax4 = axes[1, 1]
    ax4.hist(df_clean['rr_ratio'], bins=50, alpha=0.7, color='green', edgecolor='black')
    ax4.set_xlabel('Risk-Reward Ratio')
    ax4.set_ylabel('Frequency')
    ax4.set_title('Risk-Reward Ratio Distribution')
    ax4.axvline(1.8, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Min Expected: 1.8')
    ax4.axvline(3.0, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Max Expected: 3.0')
    ax4.axvline(df_clean['rr_ratio'].mean(), color='blue', linestyle='-',
                linewidth=2, label=f'Mean: {df_clean["rr_ratio"].mean():.2f}')
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')

    # 5. Scatter: Entry Price vs SL Multiplier
    ax5 = axes[2, 0]
    scatter = ax5.scatter(df_clean['entry_price'], df_clean['sl_atr_multiplier'],
                          c=df_clean['atr_percent'], cmap='viridis', alpha=0.6, s=30)
    ax5.set_xlabel('Entry Price')
    ax5.set_ylabel('SL-ATR Multiplier')
    ax5.set_title('Entry Price vs SL Multiplier (colored by ATR%)')
    plt.colorbar(scatter, ax=ax5, label='ATR %')
    ax5.grid(True, alpha=0.3)

    # 6. Comparison: LONG vs SHORT
    ax6 = axes[2, 1]
    direction_data = []
    direction_labels = []
    for direction in df_clean['direction'].unique():
        direction_data.append(df_clean[df_clean['direction'] == direction]['sl_atr_multiplier'])
        direction_labels.append(direction.upper())

    bp = ax6.boxplot(direction_data, labels=direction_labels, patch_artist=True)
    for patch, color in zip(bp['boxes'], ['lightblue', 'lightgreen']):
        patch.set_facecolor(color)

    ax6.set_ylabel('SL-ATR Multiplier')
    ax6.set_title('SL Multiplier Comparison: LONG vs SHORT')
    ax6.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()

    # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆØ¯Ø§Ø±
    output_path = Path(__file__).parent / 'sl_target_analysis.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Visualization saved to: {output_path}")

    # Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø± (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†)
    try:
        plt.show()
    except:
        print("â„¹ï¸  Display not available, chart saved to file only")


def generate_summary_report(df):
    """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ"""

    print("\n" + "="*80)
    print("ğŸ“‹ FINAL SUMMARY REPORT")
    print("="*80)

    df_clean = df.dropna(subset=['sl_atr_multiplier', 'rr_ratio'])

    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
    sl_cv = (df['sl_distance'].std() / df['sl_distance'].mean()) * 100
    atr_correlation = df.dropna(subset=['atr', 'sl_distance'])['atr'].corr(
        df.dropna(subset=['atr', 'sl_distance'])['sl_distance']
    )

    avg_multiplier = df_clean['sl_atr_multiplier'].mean()
    avg_rr = df_clean['rr_ratio'].mean()

    rr_in_range = df_clean['rr_ratio'].between(1.8, 3.0).sum()
    rr_pct = (rr_in_range / len(df_clean)) * 100

    print("\nâœ… KEY FINDINGS:")
    print("-" * 80)
    print(f"1. SL Variability (CV): {sl_cv:.2f}% - {'HIGH âœ…' if sl_cv > 20 else 'LOW âŒ'}")
    print(f"2. ATR Correlation: {atr_correlation:.4f} - {'STRONG âœ…' if atr_correlation > 0.8 else 'WEAK âŒ'}")
    print(f"3. Average SL Multiplier: {avg_multiplier:.2f}x ATR")
    print(f"4. Average RR Ratio: {avg_rr:.2f}")
    print(f"5. RR Ratios in Range (1.8-3.0): {rr_pct:.1f}% - {'GOOD âœ…' if rr_pct > 80 else 'NEEDS IMPROVEMENT âš ï¸'}")

    print("\nğŸ¯ CONCLUSION:")
    print("-" * 80)

    # ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    is_dynamic_sl = sl_cv > 20 and atr_correlation > 0.5
    is_dynamic_target = rr_pct > 50

    if is_dynamic_sl and is_dynamic_target:
        print("âœ… CONFIRMED: Stop Loss and Target are DYNAMIC and ATR-based")
        print("   â€¢ SL varies based on ATR and volatility regime")
        print("   â€¢ Target follows RR ratio guidelines")
        print("   â€¢ System behaves as documented")
    elif is_dynamic_sl:
        print("âš ï¸  PARTIAL: Stop Loss is DYNAMIC but Target needs review")
        print("   â€¢ SL varies based on ATR")
        print("   â€¢ Target RR ratios have high deviation")
    elif is_dynamic_target:
        print("âš ï¸  PARTIAL: Target is DYNAMIC but Stop Loss needs review")
        print("   â€¢ Target follows RR guidelines")
        print("   â€¢ SL shows fixed or semi-fixed behavior")
    else:
        print("âŒ WARNING: Both SL and Target show signs of being FIXED or having issues")
        print("   â€¢ Low variability in SL distances")
        print("   â€¢ Weak correlation with ATR")
        print("   â€¢ RR ratios outside expected range")

    print("\n" + "="*80)


def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""

    print("\n" + "="*80)
    print("ğŸ” DYNAMIC STOP LOSS & TARGET VERIFICATION")
    print("="*80)
    print("\nThis script verifies whether Stop Loss and Target values are:")
    print("  â€¢ DYNAMIC (varying based on ATR and market conditions)")
    print("  â€¢ FIXED (constant values)")
    print("\n" + "="*80)

    # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ CSV
    csv_path = Path(__file__).parent.parent / 'backtest_results' / 'v2_20251119_191447' / 'trades.csv'

    if not csv_path.exists():
        print(f"âŒ ERROR: File not found: {csv_path}")
        return

    try:
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        df = load_trades(csv_path)

        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§
        df = calculate_sl_metrics(df)

        # ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        analyze_sl_variability(df)
        analyze_atr_correlation(df)
        analyze_sl_multipliers(df)
        analyze_rr_ratios(df)
        analyze_by_direction(df)

        # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
        create_visualizations(df)

        # Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
        generate_summary_report(df)

        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„ Ø¯Ø± CSV
        output_csv = Path(__file__).parent / 'sl_analysis_results.csv'
        analysis_df = df[['trade_id', 'direction', 'entry_price', 'stop_loss',
                          'take_profit', 'atr', 'atr_percent', 'volatility_regime',
                          'sl_distance', 'target_distance', 'sl_atr_multiplier', 'rr_ratio']]
        analysis_df.to_csv(output_csv, index=False)
        print(f"\nğŸ’¾ Detailed analysis saved to: {output_csv}")

        print("\nâœ… Analysis completed successfully!")

    except Exception as e:
        print(f"\nâŒ ERROR: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
