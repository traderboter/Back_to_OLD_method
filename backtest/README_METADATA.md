# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Metadata Ø¯Ø± Backtest

## Ù…Ù‚Ø¯Ù…Ù‡

Ø§Ø² Ø§ÛŒÙ† Ø¨Ù‡ Ø¨Ø¹Ø¯ØŒ Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¯Ø± backtest Ø´Ø§Ù…Ù„ ÛŒÚ© Ø³ØªÙˆÙ† `metadata_json` Ø§Ø³Øª Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù…Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø±Ø§ Ø¯Ø± Ø®ÙˆØ¯ Ø¯Ø§Ø±Ø¯.

## Ø³Ø§Ø®ØªØ§Ø± Metadata

### 1. Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ù„ÛŒ

```json
{
  "aggregation_method": "multi_timeframe_old_system",
  "direction": "LONG",
  "final_score": 75.5,
  "alignment_factor": 0.85,
  "volume_factor": 0.90,
  "htf_factor": 1.2,
  "volatility_factor": 0.95
}
```

### 2. Confidence Metrics

```json
{
  "confidence": {
    "level": "high",
    "overall": 0.82,
    "timeframe_consensus": 0.85,
    "score_quality": 0.78,
    "direction_clarity": 0.88,
    "htf_alignment": 0.90,
    "volume_confirmation": 0.90,
    "is_uncertain": false,
    "requires_review": false
  }
}
```

### 3. Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù‡Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…

Ø¨Ø±Ø§ÛŒ Ù‡Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… (5m, 15m, 1h, 4h):

```json
{
  "timeframes": {
    "1h": {
      "indicators": {
        "close": 45123.50,
        "rsi": 58.3,
        "macd": 88.2,
        "macd_signal": 75.1,
        "ema_20": 44900.0,
        "ema_50": 44700.0,
        "volume": 8500000
      },
      "analyzers": {
        "trend": {
          "direction": "bullish",
          "strength": 8.2,
          "phase": "early"
        },
        "momentum": {
          "direction": "bullish",
          "strength": 7.8,
          "macd_market_type": "A_bullish_strong"
        },
        "patterns": {
          "strongest_pattern": {
            "name": "hammer",
            "confidence": 0.78,
            "candles_ago": 1
          }
        },
        "volume": {
          "is_confirmed": true,
          "strength": 1.35,
          "trend": "increasing"
        }
      },
      "signal_direction": "LONG",
      "signal_score": 78.1,
      "volume_confirmed": true,
      "htf_aligned": true
    }
  }
}
```

## Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

### 1. Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ CSV

```python
import pandas as pd
import json

# Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ØªØ§ÛŒØ¬ backtest
df = pd.read_csv('backtest_results/v2_20251118_044031/trades.csv')

# Parse Ú©Ø±Ø¯Ù† metadata
df['metadata'] = df['metadata_json'].apply(lambda x: json.loads(x) if x != '{}' else {})

# Ù†Ù…Ø§ÛŒØ´ Ø§ÙˆÙ„ÛŒÙ† Ù…Ø¹Ø§Ù…Ù„Ù‡
print(df.iloc[0]['metadata'])
```

### 2. ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§

```python
# Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…ÙˆÙÙ‚ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡
winning_trades = df[df['realized_pnl'] > 0]

patterns = []
for _, trade in winning_trades.iterrows():
    metadata = trade['metadata']
    if metadata and 'timeframes' in metadata:
        for tf, tf_data in metadata['timeframes'].items():
            if 'analyzers' in tf_data and 'patterns' in tf_data['analyzers']:
                pattern = tf_data['analyzers']['patterns'].get('strongest_pattern')
                if pattern:
                    patterns.append({
                        'trade_id': trade['trade_id'],
                        'timeframe': tf,
                        'pattern': pattern['name'],
                        'confidence': pattern['confidence'],
                        'pnl': trade['realized_pnl']
                    })

patterns_df = pd.DataFrame(patterns)
print(patterns_df.groupby('pattern')['pnl'].agg(['count', 'mean', 'sum']))
```

### 3. ØªØ­Ù„ÛŒÙ„ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§

```python
# Ø¨Ø±Ø±Ø³ÛŒ RSI Ø¯Ø± Ø²Ù…Ø§Ù† ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ù…Ø¹Ø§Ù…Ù„Ø§Øª
for _, trade in df.iterrows():
    metadata = trade['metadata']
    if metadata and 'timeframes' in metadata:
        for tf, tf_data in metadata['timeframes'].items():
            if 'indicators' in tf_data:
                rsi = tf_data['indicators'].get('rsi')
                print(f"Trade {trade['trade_id']} - {tf} RSI: {rsi:.1f}")
```

### 4. ØªØ­Ù„ÛŒÙ„ Confidence

```python
# Ù…Ø¹Ø§Ù…Ù„Ø§ØªÛŒ Ú©Ù‡ confidence Ù¾Ø§ÛŒÛŒÙ† Ø¯Ø§Ø´ØªÙ†Ø¯
low_confidence = []
for _, trade in df.iterrows():
    metadata = trade['metadata']
    if metadata and 'confidence' in metadata:
        conf = metadata['confidence']
        if conf.get('overall', 1.0) < 0.7:
            low_confidence.append({
                'trade_id': trade['trade_id'],
                'confidence': conf['overall'],
                'level': conf['level'],
                'pnl': trade['realized_pnl']
            })

low_conf_df = pd.DataFrame(low_confidence)
print(f"Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§ confidence Ù¾Ø§ÛŒÛŒÙ†: {len(low_conf_df)}")
print(f"PnL Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†: {low_conf_df['pnl'].mean():.2f}")
```

### 5. ØªØ­Ù„ÛŒÙ„ Multi-Timeframe Consensus

```python
# Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ø§Ù‡Ù†Ú¯ÛŒ Ø¨ÛŒÙ† ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
high_consensus = df[
    df['metadata'].apply(
        lambda m: m.get('confidence', {}).get('timeframe_consensus', 0) > 0.85
    )
]

print(f"Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§ consensus Ø¨Ø§Ù„Ø§: {len(high_consensus)}")
print(f"Win rate: {(high_consensus['realized_pnl'] > 0).mean():.1%}")
```

## Ù…ÙˆØ§Ø±Ø¯ Ù‚Ø§Ø¨Ù„ ØªØ­Ù„ÛŒÙ„

Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² metadata Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯:

âœ… **Ø§Ù„Ú¯ÙˆÙ‡Ø§:**
- Ú©Ø¯Ø§Ù… Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ù…ÙˆÙÙ‚â€ŒØªØ±Ù†Ø¯ØŸ
- Ø¯Ø± Ú†Ù‡ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ØªØ±Ù†Ø¯ØŸ
- confidence Ø§Ù„Ú¯Ùˆ Ú†Ù‡ ØªØ§Ø«ÛŒØ±ÛŒ Ø¨Ø± Ù†ØªÛŒØ¬Ù‡ Ø¯Ø§Ø±Ø¯ØŸ

âœ… **Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§:**
- Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± RSI Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯
- ØªØ§Ø«ÛŒØ± MACD market type Ø¨Ø± Ù…ÙˆÙÙ‚ÛŒØª
- Ù†Ù‚Ø´ EMA alignment Ø¯Ø± Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§

âœ… **Confidence:**
- Ø¢ÛŒØ§ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§ confidence Ø¨Ø§Ù„Ø§ Ù…ÙˆÙÙ‚â€ŒØªØ±Ù†Ø¯ØŸ
- Ú†Ù‡ Ø¹ÙˆØ§Ù…Ù„ÛŒ confidence Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ØŸ
- Ø¢ÛŒØ§ Ù…Ø¹Ø§Ù…Ù„Ø§Øª uncertain Ø¨Ø§ÛŒØ¯ Ø±Ø¯ Ø´ÙˆÙ†Ø¯ØŸ

âœ… **Multi-Timeframe:**
- Ú†Ù‡ Ù…ÛŒØ²Ø§Ù† consensus Ø¨ÛŒÙ† TF Ù‡Ø§ Ù†ÛŒØ§Ø² Ø§Ø³ØªØŸ
- Ú©Ø¯Ø§Ù… ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§ Ù…Ù‡Ù…â€ŒØªØ±Ù†Ø¯ØŸ
- ØªØ§Ø«ÛŒØ± HTF alignment Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ

âœ… **Trend Phase:**
- Ú©Ø¯Ø§Ù… ÙØ§Ø² trend Ù…ÙˆÙÙ‚â€ŒØªØ± Ø§Ø³ØªØŸ (early, developing, mature, late)
- Ø¢ÛŒØ§ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¯Ø± ÙØ§Ø² late Ø±ÛŒØ³Ú© Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŸ

âœ… **Volume Confirmation:**
- ØªØ§Ø«ÛŒØ± ØªØ§ÛŒÛŒØ¯ Ø­Ø¬Ù… Ø¨Ø± Ù…ÙˆÙÙ‚ÛŒØª
- Ú†Ù‡ Ù…ÛŒØ²Ø§Ù† Ø§Ø² Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…ÙˆÙÙ‚ volume confirmed Ø¨ÙˆØ¯Ù†Ø¯ØŸ

## Ù…Ø«Ø§Ù„ Ø¬Ø§Ù…Ø¹: Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ­Ù„ÛŒÙ„

```python
import pandas as pd
import json
import matplotlib.pyplot as plt

def analyze_backtest_metadata(csv_path):
    """ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ metadata Ø§Ø² backtest"""

    # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡
    df = pd.read_csv(csv_path)
    df['metadata'] = df['metadata_json'].apply(
        lambda x: json.loads(x) if x != '{}' else {}
    )

    # ÙÛŒÙ„ØªØ± Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§ metadata
    df_with_meta = df[df['metadata'].apply(lambda x: bool(x))]

    print(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª: {len(df)}")
    print(f"Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø§ metadata: {len(df_with_meta)}")

    # ØªØ­Ù„ÛŒÙ„ confidence
    df_with_meta['confidence_overall'] = df_with_meta['metadata'].apply(
        lambda m: m.get('confidence', {}).get('overall', 0)
    )
    df_with_meta['confidence_level'] = df_with_meta['metadata'].apply(
        lambda m: m.get('confidence', {}).get('level', 'unknown')
    )

    print("\n=== ØªØ­Ù„ÛŒÙ„ Confidence ===")
    print(df_with_meta.groupby('confidence_level').agg({
        'realized_pnl': ['count', 'mean', 'sum'],
        'confidence_overall': 'mean'
    }))

    # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§
    print("\n=== Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡ ===")
    patterns = []
    for _, trade in df_with_meta.iterrows():
        metadata = trade['metadata']
        if 'timeframes' in metadata:
            for tf, tf_data in metadata['timeframes'].items():
                analyzers = tf_data.get('analyzers', {})
                pattern_data = analyzers.get('patterns', {})
                strongest = pattern_data.get('strongest_pattern')
                if strongest:
                    patterns.append({
                        'pattern': strongest['name'],
                        'confidence': strongest['confidence'],
                        'timeframe': tf,
                        'pnl': trade['realized_pnl']
                    })

    if patterns:
        patterns_df = pd.DataFrame(patterns)
        print(patterns_df.groupby('pattern').agg({
            'pnl': ['count', 'mean', 'sum'],
            'confidence': 'mean'
        }).round(2))

    # Ø±Ø³Ù… Ù†Ù…ÙˆØ¯Ø§Ø±
    plt.figure(figsize=(12, 6))

    # Ù†Ù…ÙˆØ¯Ø§Ø± 1: PnL Ø¨Ø± Ø§Ø³Ø§Ø³ confidence
    plt.subplot(1, 2, 1)
    df_with_meta.plot.scatter(
        x='confidence_overall',
        y='realized_pnl',
        c='realized_pnl',
        cmap='RdYlGn',
        ax=plt.gca()
    )
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)
    plt.title('PnL vs Confidence')
    plt.xlabel('Overall Confidence')
    plt.ylabel('Realized PnL (USDT)')

    # Ù†Ù…ÙˆØ¯Ø§Ø± 2: ØªÙˆØ²ÛŒØ¹ confidence
    plt.subplot(1, 2, 2)
    df_with_meta['confidence_overall'].hist(bins=20)
    plt.title('Distribution of Confidence')
    plt.xlabel('Confidence')
    plt.ylabel('Count')

    plt.tight_layout()
    plt.savefig('backtest_metadata_analysis.png')
    print("\nğŸ“Š Ù†Ù…ÙˆØ¯Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: backtest_metadata_analysis.png")

# Ø§Ø³ØªÙØ§Ø¯Ù‡:
# analyze_backtest_metadata('backtest_results/v2_20251118_044031/trades.csv')
```

## Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² metadata Ú©Ø§Ù…Ù„ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯:
- Ø¯Ù‚ÛŒÙ‚Ø§ Ø¨Ø¯Ø§Ù†ÛŒØ¯ Ú†Ø±Ø§ Ù‡Ø± Ù…Ø¹Ø§Ù…Ù„Ù‡ Ø¨Ø§Ø² Ø´Ø¯
- Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ùˆ Ø´Ø±Ø§ÛŒØ· Ø±Ø§ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©Ù†ÛŒØ¯
- Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø±Ø§ Ø¨Ù‡ÛŒÙ†Ù‡ Ú©Ù†ÛŒØ¯
- Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù¾Ø±Ø±ÛŒØ³Ú© Ø±Ø§ Ø§Ø² Ù‚Ø¨Ù„ ØªØ´Ø®ÛŒØµ Ø¯Ù‡ÛŒØ¯
- Ú©ÛŒÙÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡Ø¨ÙˆØ¯ Ø¨Ø®Ø´ÛŒØ¯

**ØªÙˆØ¬Ù‡:** Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ù†Ù…ÙˆÙ†Ù‡ Ú©Ø§Ù…Ù„ metadataØŒ ÙØ§ÛŒÙ„ `test_metadata_example.py` Ø±Ø§ Ø§Ø¬Ø±Ø§ Ú©Ù†ÛŒØ¯:
```bash
python test_metadata_example.py
```
